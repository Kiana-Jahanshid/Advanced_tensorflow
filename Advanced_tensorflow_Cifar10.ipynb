{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "D708XPkBW6_m"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense , Flatten , Conv2D , MaxPooling2D , Dropout"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CIFAR10 = keras.datasets.cifar10\n",
        "\n",
        "(x_train , y_train) , (x_test , y_test ) = CIFAR10.load_data()\n",
        "x_train , x_test = x_train/255.0 , x_test/255.0"
      ],
      "metadata": {
        "id": "Gt4RYO54XWUn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[2].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g02f9IZWYIeW",
        "outputId": "3d5e2e58-d5c6-4ebe-a16a-2d8c841c81ba"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding batch size"
      ],
      "metadata": {
        "id": "dL_ReR_QYZCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train , y_train)).batch(32).shuffle(buffer_size=1000)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test , y_test)).batch(32)"
      ],
      "metadata": {
        "id": "vykaPmm7YW5g"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1D8vtlPejOAw",
        "outputId": "00885e62-25dc-4b21-8c29-19ee49aeb179"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv2D_1 = Conv2D(16 , (3,3) , activation=\"relu\" )\n",
        "    self.conv2D_11 = Conv2D(32 , (3,3) , activation=\"relu\" )\n",
        "    self.conv2D_2 = Conv2D(64 , (3,3) , activation=\"relu\" )\n",
        "    self.conv2D_22 = Conv2D(128 , (3,3) , activation=\"relu\" )\n",
        "    self.maxpool2D = MaxPooling2D()\n",
        "    self.dropout = Dropout(0.3)\n",
        "    self.dropout2 = Dropout(0.5)\n",
        "    self.flatten = Flatten()\n",
        "    self.dense1 = Dense(1000 , activation=\"relu\")\n",
        "    self.dense2 = Dense(10 , activation=\"softmax\")\n",
        "\n",
        "  def call(self , x):\n",
        "    x = self.conv2D_1(x)\n",
        "    x = self.conv2D_11(x)\n",
        "    x = self.maxpool2D(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.conv2D_2(x)\n",
        "    x = self.conv2D_22(x)\n",
        "    x = self.maxpool2D(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.dense1(x)\n",
        "    x = self.dropout2(x)\n",
        "    x = self.dense2(x)\n",
        "    return x\n",
        "\n",
        "model = MyModel()"
      ],
      "metadata": {
        "id": "eDXb5SyoZNcW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main loss function\n",
        "loss_function = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0001)"
      ],
      "metadata": {
        "id": "m8-j7qioapyk"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean()\n",
        "test_loss = tf.keras.metrics.Mean()\n",
        "\n",
        "train_acc = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "test_acc = tf.keras.metrics.SparseCategoricalAccuracy()"
      ],
      "metadata": {
        "id": "tHfEFk67bK76"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "W1VdyENPcQS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train(images , labels):\n",
        "    with tf.GradientTape() as tape :\n",
        "      prediction = model(images)\n",
        "      loss = loss_function(y_true=labels , y_pred=prediction)\n",
        "\n",
        "    gradients = tape.gradient(loss , model.trainable_variables)\n",
        "    optimizer.apply_gradients(grads_and_vars= zip(gradients , model.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_acc(labels, prediction)"
      ],
      "metadata": {
        "id": "CBJTrfGrcPUR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def test(images , labels):\n",
        "  prediction = model(images)\n",
        "  loss = loss_function(y_true=labels , y_pred=prediction)\n",
        "  test_loss(loss)\n",
        "  test_acc(labels , prediction)"
      ],
      "metadata": {
        "id": "i9BOGyHtd--u"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 25\n",
        "for epoch in range(epochs):\n",
        "  train_loss.reset_states()\n",
        "  train_acc.reset_states()\n",
        "  test_loss.reset_states()\n",
        "  test_acc.reset_states()\n",
        "\n",
        "  #train\n",
        "  for images , labels in train_dataset :\n",
        "    train(images , labels)\n",
        "\n",
        "  # test\n",
        "  for images , labels in test_dataset :\n",
        "    test(images , labels)\n",
        "\n",
        "\n",
        "  print(\"epoch:\" , epoch + 1  ,\n",
        "        f\"Train Loss: {train_loss.result()}\" ,\n",
        "        f\"Train Acc: {train_acc.result()}\" ,\n",
        "        f\"Test loss: {test_loss.result()}\",\n",
        "        f\"Test Acc: {test_acc.result()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ck6RT0fVeVcA",
        "outputId": "4d5fda0c-bdc1-4f74-d9c1-9af4c07ba11f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1 Train Loss: 1.7218892574310303 Train Acc: 0.37770000100135803 Test loss: 1.4796860218048096 Test Acc: 0.46389999985694885\n",
            "epoch: 2 Train Loss: 1.3854135274887085 Train Acc: 0.5043399930000305 Test loss: 1.2721941471099854 Test Acc: 0.5482000112533569\n",
            "epoch: 3 Train Loss: 1.2347691059112549 Train Acc: 0.5632200241088867 Test loss: 1.1947051286697388 Test Acc: 0.5748000144958496\n",
            "epoch: 4 Train Loss: 1.1271772384643555 Train Acc: 0.6043000221252441 Test loss: 1.1196439266204834 Test Acc: 0.6057999730110168\n",
            "epoch: 5 Train Loss: 1.0395210981369019 Train Acc: 0.6358799934387207 Test loss: 1.047363042831421 Test Acc: 0.6326000094413757\n",
            "epoch: 6 Train Loss: 0.9664450287818909 Train Acc: 0.6621800065040588 Test loss: 0.9778339862823486 Test Acc: 0.6553000211715698\n",
            "epoch: 7 Train Loss: 0.8990380764007568 Train Acc: 0.6891599893569946 Test loss: 1.0230090618133545 Test Acc: 0.6435999870300293\n",
            "epoch: 8 Train Loss: 0.83841472864151 Train Acc: 0.7106199860572815 Test loss: 0.9394715428352356 Test Acc: 0.6751999855041504\n",
            "epoch: 9 Train Loss: 0.7835736274719238 Train Acc: 0.7317399978637695 Test loss: 0.949824333190918 Test Acc: 0.6761999726295471\n",
            "epoch: 10 Train Loss: 0.7301422953605652 Train Acc: 0.7523400187492371 Test loss: 0.9026781916618347 Test Acc: 0.6930000185966492\n",
            "epoch: 11 Train Loss: 0.6776084899902344 Train Acc: 0.769320011138916 Test loss: 0.9118570685386658 Test Acc: 0.6962000131607056\n",
            "epoch: 12 Train Loss: 0.6303581595420837 Train Acc: 0.7853000164031982 Test loss: 0.8761102557182312 Test Acc: 0.7035999894142151\n",
            "epoch: 13 Train Loss: 0.5807470679283142 Train Acc: 0.8011599779129028 Test loss: 0.8636356592178345 Test Acc: 0.7095000147819519\n",
            "epoch: 14 Train Loss: 0.531647264957428 Train Acc: 0.818880021572113 Test loss: 0.8396166563034058 Test Acc: 0.7214999794960022\n",
            "epoch: 15 Train Loss: 0.48686137795448303 Train Acc: 0.835319995880127 Test loss: 0.8666660785675049 Test Acc: 0.7179999947547913\n",
            "epoch: 16 Train Loss: 0.4391272962093353 Train Acc: 0.852620005607605 Test loss: 0.8644511699676514 Test Acc: 0.7281000018119812\n",
            "epoch: 17 Train Loss: 0.3958221673965454 Train Acc: 0.8667799830436707 Test loss: 0.8974934220314026 Test Acc: 0.7245000004768372\n",
            "epoch: 18 Train Loss: 0.3518974184989929 Train Acc: 0.8816400170326233 Test loss: 0.8979445099830627 Test Acc: 0.7264000177383423\n",
            "epoch: 19 Train Loss: 0.3089754581451416 Train Acc: 0.8969799876213074 Test loss: 0.9341496229171753 Test Acc: 0.7301999926567078\n",
            "epoch: 20 Train Loss: 0.271872341632843 Train Acc: 0.9097200036048889 Test loss: 0.9990425705909729 Test Acc: 0.7246999740600586\n",
            "epoch: 21 Train Loss: 0.2333916574716568 Train Acc: 0.9224399924278259 Test loss: 1.0446844100952148 Test Acc: 0.7243000268936157\n",
            "epoch: 22 Train Loss: 0.20078574120998383 Train Acc: 0.9348000288009644 Test loss: 1.1310063600540161 Test Acc: 0.7174999713897705\n",
            "epoch: 23 Train Loss: 0.17078346014022827 Train Acc: 0.9456200003623962 Test loss: 1.2202520370483398 Test Acc: 0.7156999707221985\n",
            "epoch: 24 Train Loss: 0.14200060069561005 Train Acc: 0.9543399810791016 Test loss: 1.2525736093521118 Test Acc: 0.7160000205039978\n",
            "epoch: 25 Train Loss: 0.11963808536529541 Train Acc: 0.962440013885498 Test loss: 1.3124868869781494 Test Acc: 0.7271000146865845\n"
          ]
        }
      ]
    }
  ]
}