{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "D708XPkBW6_m"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense , Flatten , Conv2D , MaxPooling2D , Dropout , BatchNormalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Gt4RYO54XWUn"
      },
      "outputs": [],
      "source": [
        "CIFAR10 = keras.datasets.cifar10\n",
        "\n",
        "(x_train , y_train) , (x_test , y_test ) = CIFAR10.load_data()\n",
        "x_train , x_test = x_train/255.0 , x_test/255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g02f9IZWYIeW",
        "outputId": "660f1b1c-befd-4e37-cf6a-3533ce52c74a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train[2].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dL_ReR_QYZCT"
      },
      "source": [
        "# Adding batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "vykaPmm7YW5g"
      },
      "outputs": [],
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train , y_train)).batch(32).shuffle(buffer_size=1000)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test , y_test)).batch(32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1D8vtlPejOAw",
        "outputId": "723664c8-2e24-4579-9043-775656f6dc98"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkEsoDp9TdO_"
      },
      "source": [
        "# Dropout + Batch normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "eDXb5SyoZNcW"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv2D_1 = Conv2D(32 , (3,3) , activation=\"relu\" , padding=\"same\")\n",
        "    self.conv2D_2 = Conv2D(32 , (3,3) , activation=\"relu\" , padding=\"same\")\n",
        "    self.conv2D_3 = Conv2D(64 , (3,3) , activation=\"relu\" , padding=\"same\")\n",
        "    self.conv2D_4 = Conv2D(64 , (3,3) , activation=\"relu\" , padding=\"same\")\n",
        "    self.conv2D_5 = Conv2D(128 , (3,3) , activation=\"relu\" , padding=\"same\")\n",
        "    self.conv2D_6 = Conv2D(128 , (3,3) , activation=\"relu\" , padding=\"same\")\n",
        "    self.maxpool2D = MaxPooling2D()\n",
        "    self.dropout = Dropout(0.2)\n",
        "    self.dropout1 = Dropout(0.3)\n",
        "    self.dropout2 = Dropout(0.4)\n",
        "    self.dropout3 = Dropout(0.5)\n",
        "    self.flatten = Flatten()\n",
        "    self.dense1 = Dense(128 , activation=\"relu\")\n",
        "    self.dense = Dense(10 , activation=\"softmax\")\n",
        "    self.batchnorm1 = BatchNormalization()\n",
        "    self.batchnorm2 = BatchNormalization()\n",
        "    self.batchnorm3 = BatchNormalization()\n",
        "    self.batchnorm4 = BatchNormalization()\n",
        "    self.batchnorm7 = BatchNormalization()\n",
        "\n",
        "\n",
        "  def call(self , x):\n",
        "    x = self.conv2D_1(x)\n",
        "    x = self.batchnorm1(x)\n",
        "    x = self.conv2D_2(x)\n",
        "    x = self.batchnorm2(x)\n",
        "    x = self.maxpool2D(x)\n",
        "    x = self.dropout(x)\n",
        "\n",
        "    x = self.conv2D_3(x)\n",
        "    x = self.batchnorm3(x)\n",
        "    x = self.conv2D_4(x)\n",
        "    x = self.batchnorm4(x)\n",
        "    x = self.maxpool2D(x)\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    x = self.flatten(x)\n",
        "    x = self.dense1(x)\n",
        "    x = self.batchnorm7(x)\n",
        "    x = self.dropout3(x)\n",
        "    x = self.dense(x)\n",
        "    return x\n",
        "\n",
        "model = MyModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "m8-j7qioapyk"
      },
      "outputs": [],
      "source": [
        "# Main loss function\n",
        "loss_function = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "tHfEFk67bK76"
      },
      "outputs": [],
      "source": [
        "# Metrics\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean()\n",
        "test_loss = tf.keras.metrics.Mean()\n",
        "\n",
        "train_acc = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "test_acc = tf.keras.metrics.SparseCategoricalAccuracy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1VdyENPcQS7"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "CBJTrfGrcPUR"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train(images , labels):\n",
        "    with tf.GradientTape() as tape :\n",
        "      prediction = model(images)\n",
        "      loss = loss_function(y_true=labels , y_pred=prediction)\n",
        "\n",
        "    gradients = tape.gradient(loss , model.trainable_variables)\n",
        "    optimizer.apply_gradients(grads_and_vars= zip(gradients , model.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_acc(labels, prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "i9BOGyHtd--u"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def test(images , labels):\n",
        "  prediction = model(images)\n",
        "  loss = loss_function(y_true=labels , y_pred=prediction)\n",
        "  test_loss(loss)\n",
        "  test_acc(labels , prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ck6RT0fVeVcA",
        "outputId": "9a81aa3b-7adb-45a6-9c6c-f2d00a7ceed8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 1 Train Loss: 1.2753368616104126 Train Acc: 0.5448600053787231 Test loss: 0.9129331707954407 Test Acc: 0.6877999901771545\n",
            "epoch: 2 Train Loss: 0.7675131559371948 Train Acc: 0.7348600029945374 Test loss: 0.7425907850265503 Test Acc: 0.7479000091552734\n",
            "epoch: 3 Train Loss: 0.5786282420158386 Train Acc: 0.8008400201797485 Test loss: 0.7248903512954712 Test Acc: 0.7488999962806702\n",
            "epoch: 4 Train Loss: 0.45234641432762146 Train Acc: 0.8482800126075745 Test loss: 0.8509339094161987 Test Acc: 0.7466999888420105\n",
            "epoch: 5 Train Loss: 0.3482794165611267 Train Acc: 0.8826199769973755 Test loss: 0.823412299156189 Test Acc: 0.7635999917984009\n"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "  train_loss.reset_states()\n",
        "  train_acc.reset_states()\n",
        "  test_loss.reset_states()\n",
        "  test_acc.reset_states()\n",
        "\n",
        "  #train\n",
        "  for images , labels in train_dataset :\n",
        "    train(images , labels)\n",
        "\n",
        "  # test\n",
        "  for images , labels in test_dataset :\n",
        "    test(images , labels)\n",
        "\n",
        "\n",
        "  print(\"epoch:\" , epoch + 1  ,\n",
        "        f\"Train Loss: {train_loss.result()}\" ,\n",
        "        f\"Train Acc: {train_acc.result()}\" ,\n",
        "        f\"Test loss: {test_loss.result()}\",\n",
        "        f\"Test Acc: {test_acc.result()}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
